{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karthick47v2/mock-buddy/blob/base-dev/model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imi6mXi8odpl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!unzip gdrive/MyDrive/300cw/300w_96.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize data generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puFPLsLSosfv",
        "outputId": "f9b2ef4c-1ec6-4ff5-fd09-84bb0a0b6eae"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "img_size = 96\n",
        "no_channel = 1\n",
        "batch_size = 64\n",
        "\n",
        "data_gen = keras.preprocessing.image.ImageDataGenerator(validation_split=0.2)\n",
        "train_data_gen = data_gen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='./',\n",
        "    x_col='path',\n",
        "    y_col=[\n",
        "        f\"{i}\" for i in range(136)],\n",
        "    class_mode='raw',\n",
        "    subset='training',\n",
        "    batch_size=batch_size,\n",
        "    seed=42,\n",
        "    shuffle=True,\n",
        "    target_size=(img_size, img_size),\n",
        "    color_mode='grayscale'\n",
        ")\n",
        "\n",
        "validation_data_gen = data_gen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    directory='./',\n",
        "    x_col='path',\n",
        "    y_col=[\n",
        "        f\"{i}\" for i in range(136)],\n",
        "    class_mode='raw',\n",
        "    subset='validation',\n",
        "    batch_size=batch_size,\n",
        "    target_size=(\n",
        "        img_size, img_size),\n",
        "    color_mode='grayscale'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Callback functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WEnyEZduo65X"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    'checkpoint',\n",
        "    monitor='val_root_mean_squared_error',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='min',\n",
        "    save_freq=\"epoch\",\n",
        ")\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    elif (epoch % 10) == 0:\n",
        "        return lr * 0.9\n",
        "    return lr\n",
        "\n",
        "\n",
        "shd = keras.callbacks.LearningRateScheduler(scheduler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OlQiPSYpIVa",
        "outputId": "2a23083b-3014-426a-acca-5f5c7ddd865f"
      },
      "outputs": [],
      "source": [
        "model_input = keras.Input(shape=(img_size, img_size, no_channel))\n",
        "\n",
        "# # block_1\n",
        "x = keras.layers.Conv2D(filters=16, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(model_input)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=16, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=16, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "\n",
        "# # block_1\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=32, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# # block_2\n",
        "x = keras.layers.Conv2D(filters=48, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=48, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=48, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# # block_3\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=64, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# # block_4\n",
        "x = keras.layers.Conv2D(filters=80, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=80, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "x = keras.layers.Conv2D(filters=80, kernel_size=(\n",
        "    3, 3), kernel_initializer='he_uniform', activation='relu', padding='same')(x)\n",
        "x = keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = keras.layers.BatchNormalization()(x)\n",
        "\n",
        "\n",
        "# # last block\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dense(units=136, kernel_initializer='he_uniform')(x)\n",
        "\n",
        "model = keras.Model(model_input, x)\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.004),\n",
        "              loss='mean_squared_error', metrics=[keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(train_data_gen, epochs=200, batch_size=batch_size,\n",
        "                    validation_data=validation_data_gen, callbacks=[shd, model_checkpoint])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6u330GZQp7i8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "my_model = keras.models.load_model('checkpoint')\n",
        "\n",
        "# challenging dataset\n",
        "test_df = pd.read_csv('test_ibug.csv')\n",
        "\n",
        "# # common dataset\n",
        "# helen_test_df, lfpw_test_df = pd.read_csv('test_helen.csv'), pd.read_csv('test_lfpw.csv')\n",
        "# test_df = pd.concat([helen_test_df, lfpw_test_df], axis=0)\n",
        "\n",
        "image = [cv2.imread('./' + row.iloc[0], flags=cv2.IMREAD_GRAYSCALE).reshape(96, 96, 1)\n",
        "         for idx, row in test_df.iterrows()]\n",
        "\n",
        "y_hat = []\n",
        "for img in image:\n",
        "    y_hat.append(my_model.predict(np.expand_dims(img, 0)))\n",
        "\n",
        "\n",
        "val = 0\n",
        "result = []\n",
        "i = 0\n",
        "for idx, row in test_df.iterrows():\n",
        "    y_true, y_pred = row.iloc[1:137].values.reshape(\n",
        "        68, 2), y_hat[i].reshape(68, 2)\n",
        "    i += 1\n",
        "    iod = np.linalg.norm(y_true[36]-y_true[45])\n",
        "    m = 0\n",
        "    for j in range(68):\n",
        "        m = m + np.linalg.norm(y_pred[j]-y_true[j])\n",
        "    result.append(m / (68 * iod))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FB40Q5H4CHhH",
        "outputId": "52d543ba-aa2f-49c9-d3e4-1c1e6001387f"
      },
      "outputs": [],
      "source": [
        "print(f\"Cumalative: {sum(result)}\")\n",
        "print(f\"Avg: {sum(result)/len(y_hat)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "4kjH7DkuChqT",
        "outputId": "eb9221f2-0225-4ff4-a2b4-64531fbaafe1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "my_model = keras.models.load_model('checkpoint')\n",
        "\n",
        "train_df = pd.read_csv('test.csv')\n",
        "image = cv2.imread(\n",
        "    './' + train_df.iloc[100, 0], flags=cv2.IMREAD_GRAYSCALE).reshape(96, 96, 1)\n",
        "plt.imshow(image.reshape(96, 96))\n",
        "y_hat = (my_model.predict(np.expand_dims(image, 0)))\n",
        "plt.scatter(y_hat[0][:136:2], y_hat[0][1:136:2], s=3, c='r')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNyofVeZR60yDOK2xeVSRyZ",
      "include_colab_link": true,
      "name": "model_train.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "81e1bd27a5e308dfbd17b1ddd48d19559a1bcbed88e95a2e727928e958f9b7b9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
